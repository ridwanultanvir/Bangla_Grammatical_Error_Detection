{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hannah/anaconda3/envs/cs6207/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['ADJ', \n",
    "            'ADJ:FORM', \n",
    "            'ADV', \n",
    "            'CONJ', \n",
    "            'CONTR', \n",
    "            'DET', \n",
    "            'MORPH', \n",
    "            'NOUN', \n",
    "            'NOUN:INFL',\n",
    "            'NOUN:NUM', \n",
    "            'NOUN:POSS', \n",
    "            'ORTH', \n",
    "            'OTHER', \n",
    "            'PART', \n",
    "            'PREP', \n",
    "            'PRON', \n",
    "            'PUNCT', \n",
    "            'SPELL', \n",
    "            'VERB', \n",
    "            'VERB:FORM', \n",
    "            'VERB:INFL', \n",
    "            'VERB:SVA',\n",
    "            'VERB:TENSE', \n",
    "            'WO']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet('../data/lang-8/train_tagged.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_irlbi(labels):\n",
    "    sums = labels.sum(axis=0)\n",
    "    max_count = sums.max()\n",
    "    irlbi = max_count / sums\n",
    "    return irlbi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_ir(labels):\n",
    "    irlbi = get_irlbi(labels)\n",
    "    mean_ir = irlbi.mean()\n",
    "    return mean_ir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp_ros(dataset, percent=10):\n",
    "    to_clone = math.ceil(percent/100 * len(dataset))\n",
    "    labels = dataset['label'].to_numpy()\n",
    "    num_labels = len(labels[0])\n",
    "    labels = np.concatenate(labels).reshape(-1, num_labels)\n",
    "    mean_ir = get_mean_ir(labels)\n",
    "    irlbis = get_irlbi(labels)\n",
    "    np_dataset = dataset.to_numpy()\n",
    "    new_dataset = np.copy(np_dataset)\n",
    "\n",
    "    bags = {}\n",
    "\n",
    "    for i in range(num_labels):\n",
    "        irlbi = irlbis[i]\n",
    "        if irlbi > mean_ir:\n",
    "            bags[i] = np.where(labels[:,i]==1)[0]\n",
    "\n",
    "    label_counts = labels.sum(axis=0)\n",
    "    to_add = (label_counts.max()/mean_ir).round() - label_counts[list(bags.keys())]\n",
    "\n",
    "    if to_add.sum() > to_clone:\n",
    "        total_diff = to_add.sum() - to_clone\n",
    "\n",
    "        for i in range(len(bags)):\n",
    "            to_subtract = math.floor(total_diff/(len(bags) - i))\n",
    "            if to_subtract > to_add[i]:\n",
    "                total_diff -= to_add[i]\n",
    "                to_add[i] = 0\n",
    "            else:\n",
    "                to_add[i] -= to_subtract\n",
    "    \n",
    "    to_add = to_add.astype(np.int64)\n",
    "    samples = np.concatenate([np.random.choice(bags[k], to_add[i]) for i, k in enumerate(bags)])\n",
    "    new_dataset = np.concatenate([new_dataset, np_dataset[samples]])\n",
    "    \n",
    "    new_irlbis = get_irlbi(new_dataset[:,1])\n",
    "\n",
    "    print(f'Added {len(new_dataset) - len(dataset)} samples')\n",
    "    print(f'Original irlbis: {irlbis}, mean: {mean_ir}')\n",
    "    print(f'New IRLBIs: {new_irlbis}, mean: {new_irlbis.mean()}')\n",
    "\n",
    "    return pd.DataFrame(new_dataset, columns=dataset.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp_rus(dataset, percent=10):\n",
    "    to_remove = math.ceil(percent/100 * len(dataset))\n",
    "    labels = dataset['label'].to_numpy()\n",
    "    num_labels = len(labels[0])\n",
    "    labels = np.concatenate(labels).reshape(-1, num_labels)\n",
    "    mean_ir = get_mean_ir(labels)\n",
    "    irlbis = get_irlbi(labels)\n",
    "    np_dataset = dataset.to_numpy()\n",
    "\n",
    "    bags = {}\n",
    "\n",
    "    for i in range(num_labels):\n",
    "        irlbi = irlbis[i]\n",
    "        if irlbi < mean_ir:\n",
    "            bags[i] = np.where(labels[:,i]==1)[0]\n",
    "\n",
    "    label_counts = labels.sum(axis=0)\n",
    "    to_remove_per_label = label_counts[list(bags.keys())] - (label_counts.max()/mean_ir).round()\n",
    "\n",
    "    if to_remove_per_label.sum() > to_remove:\n",
    "        total_diff = to_remove_per_label.sum() - to_remove\n",
    "\n",
    "        for i in range(len(bags)):\n",
    "            to_subtract = math.floor(total_diff/(len(bags) - i))\n",
    "            if to_subtract > to_remove_per_label[i]:\n",
    "                total_diff -= to_remove_per_label[i]\n",
    "                to_remove_per_label[i] = 0\n",
    "            else:\n",
    "                to_remove_per_label[i] -= to_subtract\n",
    "\n",
    "    to_remove_per_label = to_remove_per_label.astype(np.int64)\n",
    "    samples = np.concatenate([np.random.choice(bags[k], to_remove_per_label[i]) for i, k in enumerate(bags)])\n",
    "\n",
    "    new_dataset = np.delete(np_dataset, samples, axis=0)\n",
    "    \n",
    "    new_irlbis = get_irlbi(new_dataset[:,1])\n",
    "\n",
    "    print(f'Removed {len(dataset) - len(new_dataset)} samples')\n",
    "    print(f'Original irlbis: {irlbis}, mean: {mean_ir}')\n",
    "    print(f'New IRLBIs: {new_irlbis}, mean: {new_irlbis.mean()}')\n",
    "\n",
    "    return pd.DataFrame(new_dataset, columns=dataset.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 24869 samples\n",
      "Original irlbis: [ 11.5718232  167.79971388   5.22295943  16.45049088  17.99785177\n",
      "   1.54951384   8.62346065   3.80250276 163.13212796   4.59842396\n",
      "  45.92482381   4.68240883   1.          27.96328525   2.28207872\n",
      "   5.92010095   3.34809106   3.55311866   2.78388417   7.02137085\n",
      " 118.          11.12036027   2.99914341  14.42351205], mean: 27.157126931951865\n",
      "New IRLBIs: [11.5614725  28.0750115   5.12620788 16.27830031 18.01875508  1.54298685\n",
      "  8.58437401  3.79497069 28.0653249   4.54157671 27.64250113  4.69736285\n",
      "  1.         27.06010202  2.27406834  5.94479768  3.33316943  3.53679145\n",
      "  2.7831978   7.05201711 28.0491954  10.87759651  3.00645575 14.52720562], mean: 11.140560063588651\n"
     ]
    }
   ],
   "source": [
    "train_oversampled10 = mlp_ros(df, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_oversampled10.to_parquet('../data/lang-8/train_tagged_oversampled10.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 18975,   8159,  42959,  13543,  12232, 142446,  25596,  58025,\n",
       "         8147,  48443,   8307,  47024, 220208,   8429,  96842,  37151,\n",
       "        66288,  62232,  78922,  31227,   8151,  20215,  73254,  15149,\n",
       "       485910])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_oversampled10.label.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 810, 6888, 2509,  715,  476, 6324, 1177, 2516, 6853, 2564, 3699,\n",
       "       1782, 9046,  839, 4394, 1516, 3177, 2912, 3237, 1177, 6373, 1202,\n",
       "       2869,  506,    0])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_oversampled10.label.sum() - df.label.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet('../data/lang-8-en-1.0/train_tagged_oversampled10.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_parquet('../data/lang-8-en-1.0/eval_tagged.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>So , I have to get up at 7 : 00 to get to work...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sorry for the boring entry . . .</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I 'm not good at English and that is my fatal ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>You did much for me but what I did for you is ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Maybe you do n't know it .</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1026713</th>\n",
       "      <td>So when it occurred people were unable to esca...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1026714</th>\n",
       "      <td>I heard from my parents that the pollen count ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1026715</th>\n",
       "      <td>I told him my name and birth date .</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1026716</th>\n",
       "      <td>It is not very easy to understand , because it...</td>\n",
       "      <td>[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1026717</th>\n",
       "      <td>Based on the survey , childhood is indeed impo...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1026718 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      text  \\\n",
       "0        So , I have to get up at 7 : 00 to get to work...   \n",
       "1                         Sorry for the boring entry . . .   \n",
       "2        I 'm not good at English and that is my fatal ...   \n",
       "3        You did much for me but what I did for you is ...   \n",
       "4                               Maybe you do n't know it .   \n",
       "...                                                    ...   \n",
       "1026713  So when it occurred people were unable to esca...   \n",
       "1026714  I heard from my parents that the pollen count ...   \n",
       "1026715                I told him my name and birth date .   \n",
       "1026716  It is not very easy to understand , because it...   \n",
       "1026717  Based on the survey , childhood is indeed impo...   \n",
       "\n",
       "                                                     label  \n",
       "0        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, ...  \n",
       "1        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "2        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "3        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "4        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "...                                                    ...  \n",
       "1026713  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, ...  \n",
       "1026714  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, ...  \n",
       "1026715  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "1026716  [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "1026717  [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "\n",
       "[1026718 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df2.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.to_parquet('../data/lang-8-en-1.0/eval_tagged.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet('../data/lang-8-en-1.0/train_tagged_oversampled10.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "24a8be2a320db3fc78f98e0e0e2222c9eba1ced1d83542243f810a82b72a9ba3"
  },
  "kernelspec": {
   "display_name": "Python 3.7.12 ('cs6207')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
