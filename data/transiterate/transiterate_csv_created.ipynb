{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['আমেরিকা', 'এমেরিকা', 'আমেৰিকা', 'আমেরিকে', 'অমেরিকা', 'আমেরিকাঃ']\n"
     ]
    }
   ],
   "source": [
    "from google.transliteration import transliterate_word\n",
    "suggestions = transliterate_word('America', lang_code='bn')\n",
    "print(suggestions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package universal_tagset to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\universal_tagset.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('universal_tagset')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP1: eng_bn transiterate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'he', 'its', 'our', 'your', 'we', 'hadn', 'us', 'himself', 'their', 'it', 'her', 'him', 'they', 'herself', 'my', 'me', 'myself', 'his', 'yourself', 'itself', 'themselves', 'them', 'you', 'she'}\n",
      "{'in', 'out', 'during', 'below', 'that', 'before', 'if', 'into', 'o', 'on', 'of', 'between', 'through', 'by', 'over', 'after', 'than', 'off', 'with', 'at', 'about', 'for', 'until', 'as', 'under', 'from', 'because', 'while', 'against', 'theirs'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "stopwords = set(nltk.corpus.stopwords.words('english'))\n",
    "pos_tags = nltk.pos_tag(stopwords)\n",
    "pronouns = set([word.lower() for (word, tag) in pos_tags if tag in ['PRP', 'PRP$']])\n",
    "pronouns.add('us'  )\n",
    "print(pronouns)\n",
    "prepositions = set([word.lower() for (word, tag) in pos_tags if tag == 'IN'])\n",
    "print(prepositions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "# from indic_transliteration import sanscript\n",
    "\n",
    "# Read the unigram_freq.csv file\n",
    "df = pd.read_csv('unigram_freq.csv')\n",
    "\n",
    "# Remove stop words using NLTK\n",
    "stop_words = set(stopwords.words('english'))\n",
    "# ============= new add =========================\n",
    "\n",
    "df = df[~df['word'].isin(stop_words)]\n",
    "# ============= new add =========================\n",
    "df = df[~df['word'].isin(pronouns)]\n",
    "df = df[~df['word'].isin(prepositions)]\n",
    "\n",
    "# Take 50 most frequent words\n",
    "df = df.nlargest(20, 'count')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>new</td>\n",
       "      <td>1551258643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>home</td>\n",
       "      <td>1276852170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>page</td>\n",
       "      <td>1082121730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>search</td>\n",
       "      <td>1024093118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>free</td>\n",
       "      <td>1014107316</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      word       count\n",
       "26     new  1551258643\n",
       "32    home  1276852170\n",
       "37    page  1082121730\n",
       "40  search  1024093118\n",
       "41    free  1014107316"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 2)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.transliteration import transliterate_word\n",
    "# Define a function to transliterate a given string to Bengali script\n",
    "def transliterate_to_bengali(text):\n",
    "    suggestions = transliterate_word(text, lang_code='bn')\n",
    "    print(\"suggestions: \", suggestions)\n",
    "    top_suggestion = suggestions[0]\n",
    "    return top_suggestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "suggestions:  ['নিউ', 'নেয়', 'নেও', 'নাও', 'নেব', 'নয়']\n",
      "suggestions:  ['হোম', 'হোমে', 'হমে', 'হ্মে', 'হোমি', 'হামে']\n",
      "suggestions:  ['পেজ', 'পেজে', 'পাগে', 'প্যাগে', 'পাজে', 'প্রাগে']\n",
      "suggestions:  ['সার্চ', 'সার্চে', 'সারচ', 'শেয়ারছ', 'শেয়ারচ', 'সেয়ার্চ']\n",
      "suggestions:  ['ফ্রি', 'ফ্রী', 'ফেরী', 'ফরী', 'ফ্ৰী', 'ফাড়ী']\n",
      "suggestions:  ['ওয়ান', 'মনে', 'অনে', 'ণে', 'নে', 'ওনে']\n",
      "suggestions:  ['ইনফরমেশন', 'ইনফর্মাটিন', 'ইনফর্মাশন', 'ইনফর্মটিও', 'ইনফরম্যাশন', 'ইনফর্মটিওন']\n",
      "suggestions:  ['টাইম', 'টিমে', 'টীমে', 'টিম', 'তিমি', 'টাইমে']\n",
      "suggestions:  ['সাইট', 'সিটে', 'শীতে', 'দিতে', 'সীটে', 'সিটি']\n",
      "suggestions:  ['মে', 'মায়', 'মাই', 'ময়', 'মেয়ে', 'মায়া']\n",
      "suggestions:  ['নিউস', 'নিউজ', 'নেউস', 'নেওস', 'নাউস', 'নেউল']\n",
      "suggestions:  ['উসে', 'আসে', 'ওসি', 'সে', 'চুষে', 'চুসে']\n",
      "suggestions:  ['সেই', 'সেে', 'সে', 'সি', 'সী', 'সেয়ে']\n",
      "suggestions:  ['কন্টাক্ট', 'কন্ট্যাক্ট', 'কনটাক্ট', 'কংটাক্ট', 'কনট্যাক্ট', 'কন্ট্রাক্ট']\n",
      "suggestions:  ['বিসনেস', 'বুসিনেস', 'বুসিনেশ', 'বুসিনেসস', 'বুসিনেসিস', 'বুসিনাস']\n",
      "suggestions:  ['ওয়েব', 'বেবি', 'ভেবে', 'বেশ', 'বেব', 'বের']\n",
      "suggestions:  ['অল্সো', 'অলস', 'অলসো', 'লস', 'আলস', 'আল্স']\n",
      "suggestions:  ['হেল্প', 'হেলপ', 'হেল্পঃ', 'হেল্পা', 'হেঁল্প', 'হেল্পি']\n",
      "suggestions:  ['গেট', 'গেট্', 'গেটে', 'গেল', 'যেত', 'জেট']\n",
      "suggestions:  ['পাম', 'পম', 'পিম', 'প্ম', 'পর', 'পহ্ম']\n",
      "      word       count bangla\n",
      "26     new  1551258643    নিউ\n",
      "32    home  1276852170    হোম\n",
      "37    page  1082121730    পেজ\n",
      "40  search  1024093118  সার্চ\n",
      "41    free  1014107316   ফ্রি\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Add a new column 'bangla' with transliterated words\n",
    "df['bangla'] = df['word'].apply(transliterate_to_bengali)\n",
    "\n",
    "# Print the resulting DataFrame\n",
    "print(df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={'word': 'english'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('test1.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "065f01d7f979c895d1d0ceb36265384114dc012dca8df1b5cf5e1949e9669c42"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
