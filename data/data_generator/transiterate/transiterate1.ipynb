{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP1: eng_bn transiterate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['আমেরিকা', 'এমেরিকা', 'আমেৰিকা', 'আমেরিকে', 'অমেরিকা', 'আমেরিকাঃ']\n"
     ]
    }
   ],
   "source": [
    "from google.transliteration import transliterate_word\n",
    "suggestions = transliterate_word('America', lang_code='bn')\n",
    "print(suggestions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to transliterate a given string to Bengali script\n",
    "def transliterate_to_bengali(text):\n",
    "    suggestions = transliterate_word(text, lang_code='bn')\n",
    "    print(\"suggestions: \", suggestions)\n",
    "    top_suggestion = suggestions[0]\n",
    "    return top_suggestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "# from indic_transliteration import sanscript\n",
    "\n",
    "# Read the unigram_freq.csv file\n",
    "df = pd.read_csv('unigram_freq.csv')\n",
    "\n",
    "# Remove stop words using NLTK\n",
    "stop_words = set(stopwords.words('english'))\n",
    "df = df[~df['word'].isin(stop_words)]\n",
    "\n",
    "# Take 50 most frequent words\n",
    "df = df.nlargest(50, 'count')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 2)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>new</td>\n",
       "      <td>1551258643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>home</td>\n",
       "      <td>1276852170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>us</td>\n",
       "      <td>1229112622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>page</td>\n",
       "      <td>1082121730</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    word       count\n",
       "26   new  1551258643\n",
       "32  home  1276852170\n",
       "34    us  1229112622\n",
       "37  page  1082121730"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "suggestions:  ['নিউ', 'নেয়', 'নেও', 'নাও', 'নেব', 'নয়']\n",
      "suggestions:  ['হোম', 'হোমে', 'হমে', 'হ্মে', 'হোমি', 'হামে']\n",
      "suggestions:  ['উস', 'উষ', 'জুস', 'ওসি', 'ঊস', 'উঃস']\n",
      "suggestions:  ['পেজ', 'পেজে', 'পাগে', 'প্যাগে', 'পাজে', 'প্রাগে']\n",
      "    word       count transliterated_word\n",
      "26   new  1551258643                 নিউ\n",
      "32  home  1276852170                 হোম\n",
      "34    us  1229112622                  উস\n",
      "37  page  1082121730                 পেজ\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Apply the function to each word in the dataframe\n",
    "df['transliterated_word'] = df['word'].apply(transliterate_to_bengali)\n",
    "\n",
    "# Print the resulting dataframe\n",
    "print(df.head(4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['আমেরিকা', 'এমেরিকা', 'আমেৰিকা', 'আমেরিকে', 'অমেরিকা', 'আমেরিকাঃ']\n"
     ]
    }
   ],
   "source": [
    "from google.transliteration import transliterate_word\n",
    "suggestions = transliterate_word('America', lang_code='bn')\n",
    "print(suggestions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'bangla_transliterate'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [4], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnltk\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mbangla_transliterate\u001b[39;00m \u001b[39mimport\u001b[39;00m transliterate\n\u001b[0;32m      5\u001b[0m nltk\u001b[39m.\u001b[39mdownload(\u001b[39m'\u001b[39m\u001b[39mstopwords\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      7\u001b[0m \u001b[39m# Load the unigram_freq.csv file into a pandas DataFrame\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'bangla_transliterate'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from bangla_transliterate import transliterate\n",
    "\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Load the unigram_freq.csv file into a pandas DataFrame\n",
    "df = pd.read_csv('unigram_freq.csv')\n",
    "\n",
    "# Remove stop words using NLTK\n",
    "stop_words = set(nltk.corpus.stopwords.words('english'))\n",
    "df = df[~df['word'].isin(stop_words)]\n",
    "\n",
    "# Take 50 most frequent words\n",
    "df = df.nlargest(50, 'count')\n",
    "\n",
    "# Transliterate each word to Bangla\n",
    "df['word_bangla'] = df['word'].apply(transliterate)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the resulting DataFrame\n",
    "df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Load the unigram_freq.csv file into a pandas DataFrame\n",
    "df = pd.read_csv('unigram_freq.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Remove stop words using NLTK\n",
    "stop_words = set(nltk.corpus.stopwords.words('english'))\n",
    "df = df[~df['word'].isin(stop_words)]\n",
    "\n",
    "# Take 50 most frequent words\n",
    "df = df.nlargest(50, 'count')\n",
    "\n",
    "# Print the resulting DataFrame\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>new</td>\n",
       "      <td>1551258643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>home</td>\n",
       "      <td>1276852170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>us</td>\n",
       "      <td>1229112622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>page</td>\n",
       "      <td>1082121730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>search</td>\n",
       "      <td>1024093118</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      word       count\n",
       "26     new  1551258643\n",
       "32    home  1276852170\n",
       "34      us  1229112622\n",
       "37    page  1082121730\n",
       "40  search  1024093118"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "065f01d7f979c895d1d0ceb36265384114dc012dca8df1b5cf5e1949e9669c42"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
