{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_FILE = '../data/tsd_train.csv'\n",
    "TRIAL_FILE = '../data/tsd_trial.csv'\n",
    "TEST_FILE = '../data/tsd_test_spans.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(TRAIN_FILE)\n",
    "trial = pd.read_csv(TRIAL_FILE)\n",
    "test = pd.read_csv(TEST_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                               spans  \\\n",
       "0  [8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19,...   \n",
       "1                       [33, 34, 35, 36, 37, 38, 39]   \n",
       "2                                       [0, 1, 2, 3]   \n",
       "3          [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17]   \n",
       "4                       [32, 33, 34, 35, 36, 37, 38]   \n",
       "\n",
       "                                                text  \n",
       "0  Another violent and aggressive immigrant killi...  \n",
       "1  I am 56 years old, I am not your fucking junio...  \n",
       "2                  Damn, a whole family. Sad indeed.  \n",
       "3  What a knucklehead. How can anyone not know th...  \n",
       "4  \"who do you think should do the killing?\"\\n\\nA...  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>spans</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19,...</td>\n      <td>Another violent and aggressive immigrant killi...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[33, 34, 35, 36, 37, 38, 39]</td>\n      <td>I am 56 years old, I am not your fucking junio...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[0, 1, 2, 3]</td>\n      <td>Damn, a whole family. Sad indeed.</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17]</td>\n      <td>What a knucklehead. How can anyone not know th...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[32, 33, 34, 35, 36, 37, 38]</td>\n      <td>\"who do you think should do the killing?\"\\n\\nA...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(7939, 2)"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "spans    0\n",
       "text     0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "train.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                      spans  \\\n",
       "0  [15, 16, 17, 18, 19, 27, 28, 29, 30, 31]   \n",
       "1                  [29, 30, 31, 32, 33, 34]   \n",
       "2            [166, 167, 168, 169, 170, 171]   \n",
       "3                  [87, 88, 89, 90, 91, 92]   \n",
       "4                                        []   \n",
       "\n",
       "                                                text  \n",
       "0  Because he's a moron and a bigot. It's not any...  \n",
       "1  How about we stop protecting idiots and let na...  \n",
       "2  If people  were  smart, they would  Boycott th...  \n",
       "3  Trump Claimed that Russia will never invade th...  \n",
       "4  As long as your willing to pay a lot more for ...  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>spans</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[15, 16, 17, 18, 19, 27, 28, 29, 30, 31]</td>\n      <td>Because he's a moron and a bigot. It's not any...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[29, 30, 31, 32, 33, 34]</td>\n      <td>How about we stop protecting idiots and let na...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[166, 167, 168, 169, 170, 171]</td>\n      <td>If people  were  smart, they would  Boycott th...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[87, 88, 89, 90, 91, 92]</td>\n      <td>Trump Claimed that Russia will never invade th...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[]</td>\n      <td>As long as your willing to pay a lot more for ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "trial.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(690, 2)"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "trial.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "spans    0\n",
       "text     0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "trial.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "trial.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "combo = pd.concat([train,trial])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                               spans  \\\n",
       "0  [8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19,...   \n",
       "1                       [33, 34, 35, 36, 37, 38, 39]   \n",
       "2                                       [0, 1, 2, 3]   \n",
       "3          [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17]   \n",
       "4                       [32, 33, 34, 35, 36, 37, 38]   \n",
       "\n",
       "                                                text  \n",
       "0  Another violent and aggressive immigrant killi...  \n",
       "1  I am 56 years old, I am not your fucking junio...  \n",
       "2                  Damn, a whole family. Sad indeed.  \n",
       "3  What a knucklehead. How can anyone not know th...  \n",
       "4  \"who do you think should do the killing?\"\\n\\nA...  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>spans</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19,...</td>\n      <td>Another violent and aggressive immigrant killi...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[33, 34, 35, 36, 37, 38, 39]</td>\n      <td>I am 56 years old, I am not your fucking junio...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[0, 1, 2, 3]</td>\n      <td>Damn, a whole family. Sad indeed.</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17]</td>\n      <td>What a knucklehead. How can anyone not know th...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[32, 33, 34, 35, 36, 37, 38]</td>\n      <td>\"who do you think should do the killing?\"\\n\\nA...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "combo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "spans    0\n",
       "text     0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "combo.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "combo.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                        spans                  text\n",
       "100          [6, 7, 8, 9, 10]          Trump troll!\n",
       "224           [0, 1, 2, 3, 4]                Idiot!\n",
       "276           [0, 1, 2, 3, 4]                 Idiot\n",
       "363  [14, 15, 16, 17, 18, 19]  You can't fix stupid\n",
       "588      [11, 12, 13, 14, 15]     You are an idiot."
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>spans</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>100</th>\n      <td>[6, 7, 8, 9, 10]</td>\n      <td>Trump troll!</td>\n    </tr>\n    <tr>\n      <th>224</th>\n      <td>[0, 1, 2, 3, 4]</td>\n      <td>Idiot!</td>\n    </tr>\n    <tr>\n      <th>276</th>\n      <td>[0, 1, 2, 3, 4]</td>\n      <td>Idiot</td>\n    </tr>\n    <tr>\n      <th>363</th>\n      <td>[14, 15, 16, 17, 18, 19]</td>\n      <td>You can't fix stupid</td>\n    </tr>\n    <tr>\n      <th>588</th>\n      <td>[11, 12, 13, 14, 15]</td>\n      <td>You are an idiot.</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "combo[combo.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merged_df = train.merge(trial, how='inner',indicator=False)\n",
    "# new_train = train[~train.text.isin(merged_df['text'].values)]\n",
    "# new_train.to_csv('../data/modified_train.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_continuous_spans(spans):\n",
    "    continuous_spans = []\n",
    "    current_span = []\n",
    "    for i in range(len(spans)):\n",
    "        if current_span == []:\n",
    "            current_span.append(spans[i])\n",
    "            continue\n",
    "        if spans[i]==current_span[-1]+1:\n",
    "            current_span.append(spans[i])\n",
    "        else:\n",
    "            continuous_spans.append(current_span)\n",
    "            current_span = [spans[i]]\n",
    "    if(current_span!=[]):\n",
    "        continuous_spans.append(current_span)\n",
    "    return continuous_spans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if any spaces are marked in the toxic spans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_space_count(df):\n",
    "    df['space_count'] = df.apply(lambda x: np.sum([1 if x['text'][i]==' ' else 0 for i in eval(x['spans'])]),axis=1)\n",
    "    return df['space_count'].sum(), df['space_count'].mean(),  df['space_count'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['13278.00', '1.67', '7.72']\n"
     ]
    }
   ],
   "source": [
    "print(['%.2f'% i for i in get_space_count(train)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['830.00', '1.20', '4.48']\n"
     ]
    }
   ],
   "source": [
    "print(['%.2f'% i for i in get_space_count(trial)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['575.00', '0.29', '3.19']\n"
     ]
    }
   ],
   "source": [
    "print(['%.2f'% i for i in get_space_count(test)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if any words are cut across spans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_if_word_cut(text,contiguous_spans):\n",
    "    words_cuts = []\n",
    "    for i in contiguous_spans:\n",
    "        words_cut = 0\n",
    "        if i[0]==0 and i[-1]==len(text)-1:\n",
    "            words_cut = 0\n",
    "        elif i[0]==0:\n",
    "            if text[i[-1]]!=' ' and text[i[-1]+1].isalnum():\n",
    "                words_cut+=1\n",
    "        elif i[-1]==len(text)-1:\n",
    "            if text[i[0]]!=' ' and text[i[0]-1].isalnum():\n",
    "                words_cut +=1\n",
    "        else:\n",
    "            if text[i[0]]!=' ' and text[i[0]-1].isalnum():\n",
    "                words_cut +=1\n",
    "            if text[i[-1]]!=' ' and text[i[-1]+1].isalnum():\n",
    "                words_cut +=1\n",
    "        words_cuts.append(words_cut)\n",
    "    return words_cuts     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def words_cut_count(df):\n",
    "    df['contiguous_spans'] = df.apply(lambda x : get_continuous_spans(eval(x['spans'])),axis=1)\n",
    "    df['words_cut'] = df.apply(lambda x: np.sum(check_if_word_cut(x['text'],x['contiguous_spans'])),axis=1)\n",
    "    return df['words_cut'].sum(),df['words_cut'].mean(),df['words_cut'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['263.00', '0.03', '0.20']\n"
     ]
    }
   ],
   "source": [
    "print(['%.2f'% i for i in words_cut_count(train)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['26.00', '0.04', '0.23']\n"
     ]
    }
   ],
   "source": [
    "print(['%.2f'% i for i in words_cut_count(trial)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['8.00', '0.00', '0.06']\n"
     ]
    }
   ],
   "source": [
    "print(['%.2f'% i for i in words_cut_count(test)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_contiguous_spans(text,contiguous_spans):\n",
    "    return [text[i[0]:i[-1]+1] for i in contiguous_spans]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train[train['words_cut']>0].apply(lambda x: (x['text'],len(x['text']),x['spans'],x['contiguous_spans'],print_contiguous_spans(x['text'],x['contiguous_spans']),x['words_cut']),axis=1).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if any spans end or start with space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "def check_if_start_or_end_with_whitespace(text,contiguous_spans):\n",
    "    start_or_end_with_space = []\n",
    "    for i in contiguous_spans:\n",
    "        s_e = 0\n",
    "        if text[i[0]] in string.whitespace:\n",
    "            s_e+=1\n",
    "        if text[i[-1]] in string.whitespace:\n",
    "            s_e+=1\n",
    "        start_or_end_with_space.append(s_e)\n",
    "    return start_or_end_with_space "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_end_with_space(df):\n",
    "    df['start_or_end_with_space'] = df.apply(lambda x: np.sum(check_if_start_or_end_with_whitespace(x['text'],x['contiguous_spans'])),axis=1)\n",
    "    return df['start_or_end_with_space'].sum(),df['start_or_end_with_space'].mean(),df['start_or_end_with_space'].std()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['22.00', '0.00', '0.05']\n"
     ]
    }
   ],
   "source": [
    "print(['%.2f'% i for i in start_end_with_space(train)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['1.00', '0.00', '0.04']\n"
     ]
    }
   ],
   "source": [
    "print(['%.2f'% i for i in start_end_with_space(trial)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['1.00', '0.00', '0.02']\n"
     ]
    }
   ],
   "source": [
    "print(['%.2f'% i for i in start_end_with_space(test)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train[train['start_or_end_with_space']>0].apply(lambda x: (x['text'],len(x['text']),x['start_or_end_with_space'],print_contiguous_spans(x['text'],x['contiguous_spans'])),axis=1).values"
   ]
  },
  {
   "source": [
    "Clean out spans which are half in, remove trailing and beginning spaces"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_word_by_character_index(text, idx):\n",
    "    if(text[idx].isalnum()):\n",
    "        backward = idx\n",
    "        forward = idx\n",
    "        while(backward>-1 and text[backward].isalnum()):\n",
    "            backward-=1\n",
    "        while(forward<len(text) and text[forward].isalnum()):\n",
    "            forward+=1\n",
    "\n",
    "        return text[backward+1:forward], backward+1,forward-1\n",
    "    else:\n",
    "        return text[idx], idx, idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'[0, 1, 2, 3, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71]'"
      ]
     },
     "metadata": {},
     "execution_count": 38
    }
   ],
   "source": [
    "train.loc[20,'spans']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'Kill some more kids and then complain about guns, LOL the left is a joke'"
      ]
     },
     "metadata": {},
     "execution_count": 39
    }
   ],
   "source": [
    "train.loc[20,'text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "('and', 20, 22)"
      ]
     },
     "metadata": {},
     "execution_count": 40
    }
   ],
   "source": [
    "find_word_by_character_index(train.loc[20,'text'],22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def clean_text(text,contiguous_spans):\n",
    "#     new_contiguous_spans = []\n",
    "\n",
    "#     for i in contiguous_spans:\n",
    "#         start = i[0] \n",
    "#         end = i[-1]\n",
    "\n",
    "#         if start==0 and end==len(text)-1:\n",
    "#             new_contiguous_spans.append([start,end])\n",
    "\n",
    "#         elif start==0:\n",
    "#             if text[end].isalnum() and text[end+1].isalnum():\n",
    "\n",
    "#                 full_word,full_start,full_end = find_word_by_character_index(text,end)\n",
    "#                 cut_word_len = end-full_start+1\n",
    "#                 if(cut_word_len*2>=len(full_word)):\n",
    "#                     new_contiguous_spans.append([start,full_end])\n",
    "#                 else:\n",
    "#                     new_contiguous_spans.append([start,full_start-1])\n",
    "\n",
    "\n",
    "#         elif i[-1]==len(text)-1:\n",
    "#             if text[start].isalnum() and text[start-1].isalnum():\n",
    "#                 full_word, full_start,full_end = find_word_by_character_index(text,start)\n",
    "#                 cut_word_len = full_end-start+1\n",
    "#                 if(cut_word_len*2>=len(full_word)):\n",
    "#                     new_contiguous_spans.append([full_start,end])\n",
    "#                 else:\n",
    "#                     new_contiguous_spans.append([full_end+1,end])\n",
    "                \n",
    "                \n",
    "#         else:\n",
    "#             new_start = start\n",
    "#             new_end = end\n",
    "           \n",
    "#             if text[start].isalnum() and text[start-1].isalnum():\n",
    "#                 full_word, full_start,full_end = find_word_by_character_index(text,start)\n",
    "#                 cut_word_len = full_end-start+1\n",
    "#                 if(cut_word_len*2>=len(full_word)):\n",
    "#                     new_start = full_start\n",
    "#                 else:\n",
    "#                     new_start = full_end+1\n",
    "\n",
    "#             if text[end].isalnum() and text[end+1].isalnum():\n",
    "#                 full_word, full_start,full_end = find_word_by_character_index(text, end)\n",
    "#                 cut_word_len = end-full_start+1\n",
    "#                 if(cut_word_len*2>=len(full_word)):\n",
    "#                     new_end = full_end\n",
    "#                 else:\n",
    "#                     new_end = full_start-1\n",
    "#             new_contiguous_spans.append([new_start,new_end])\n",
    "#     ## Remove Spaces from span beginning and end\n",
    "\n",
    "#     newest_contiguous_spans = []\n",
    "#     for i in new_contiguous_spans:\n",
    "#         start = i[0]\n",
    "#         end = i[-1]\n",
    "#         while start<=end:\n",
    "#             if(not (text[start].isalnum()) or not (text[end].isalnum())):\n",
    "#                 if not (text[start].isalnum()):\n",
    "#                     start+=1\n",
    "#                 if not (text[end].isalnum()):\n",
    "#                     end-=1\n",
    "#             else:\n",
    "#                 break\n",
    "#         if(start<=end):\n",
    "#             newest_contiguous_spans.append([start,end])\n",
    "#     return newest_contiguous_spans\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Hello How are you sir, My name is Gunjan Chhablani?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "contiguous_spans = get_continuous_spans([1,2,3,4,6,7,11,12,13,14,15,16,17, 18, 19, 22,23,24,25,30,31,32,33,34,35,36, 41,42,43,44])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['ello', 'Ho', 're you si', ' My ', ' is Gun', 'Chha']"
      ]
     },
     "metadata": {},
     "execution_count": 44
    }
   ],
   "source": [
    "print_contiguous_spans(text,contiguous_spans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_contiguous_spans = clean_text(text,contiguous_spans)\n",
    "#print_contiguous_spans(text,new_contiguous_spans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean_train = new_train.copy()\n",
    "# clean_train['contiguous_spans'] = clean_train.apply(lambda x: clean_text(x['text'],x['contiguous_spans']),axis=1)\n",
    "# clean_trial = trial.copy()\n",
    "# clean_trial['contiguous_spans'] = clean_trial.apply(lambda x:clean_text(x['text'],x['contiguous_spans']),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#start_end_with_space(clean_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#start_end_with_space(clean_trial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def words_cut_count_clean(df):\n",
    "#     df['words_cut'] = df.apply(lambda x: np.sum(check_if_word_cut(x['text'],x['contiguous_spans'])),axis=1)\n",
    "#     return df['words_cut'].sum(),df['words_cut'].mean(),df['words_cut'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# words_cut_count_clean(clean_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# words_cut_count_clean(clean_trial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean_train.to_csv('../data/clean_train.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean_trial.to_csv('../data/clean_trial.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean_train = pd.read_csv('../data/clean_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean_trial = pd.read_csv('../data/clean_trial.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_spans_from_contiguous(contiguous_spans):\n",
    "#     spans = []\n",
    "#     for i in eval(contiguous_spans):\n",
    "#         spans+=list(range(i[0],i[-1]+1))\n",
    "#     return spans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean_train['spans'] = clean_train['contiguous_spans'].apply(get_spans_from_contiguous)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean_trial['spans'] = clean_trial['contiguous_spans'].apply(get_spans_from_contiguous)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean_train[['spans','text']].to_csv('../data/clean_train.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean_trial[['spans','text']].to_csv('../data/clean_trial.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_train.to_csv('../data/modified_train.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokens Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean_train = pd.read_csv('../data/clean_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean_trial = pd.read_csv('../data/clean_trial.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduced_train = pd.read_csv('../data/modified_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "def tokenize_text(df):\n",
    "    df['#tokens'] = df.apply(lambda x: len(tokenizer.tokenize(x['text'])),axis=1)\n",
    "    df['#words'] = df.apply(lambda x: len(x['text'].split()),axis=1)\n",
    "    df['#chars'] = df.apply(lambda x: len(x['text']),axis=1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "lists = []\n",
    "for df in [train,trial,test]:\n",
    "    tokenize_text(df)\n",
    "    lists.append(['%.2f' % i for i in (df['#tokens'].mean(),df['#tokens'].std(),df['#tokens'].max(),df['#tokens'].min())]+['%.2f' % i for i in (df['#words'].mean(),df['#words'].std(),df['#words'].max(),df['#words'].min())] +['%.2f' % i for i in (df['#chars'].mean(),df['#chars'].std(),df['#chars'].max(),df['#chars'].min())] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "|               |       0 |      1 |       2 |\n|:--------------|--------:|-------:|--------:|\n| #Tokens(mean) |   47.5  |  46.1  |   43.12 |\n| #Tokens(std)  |   45.46 |  43.82 |   39.88 |\n| #Tokens(max)  |  335    | 234    |  291    |\n| #Tokens(min)  |    1    |   1    |    2    |\n| #Words(mean)  |   35.95 |  35.01 |   32.86 |\n| #Words(std)   |   34.97 |  34.42 |   31.01 |\n| #Words(max)   |  192    | 182    |  186    |\n| #Words(min)   |    1    |   1    |    1    |\n| #Chars(mean)  |  204.57 | 199.47 |  186.41 |\n| #Chars(std)   |  201.37 | 196.63 |  178.76 |\n| #Chars(max)   | 1000    | 998    | 1000    |\n| #Chars(min)   |    4    |   5    |    6    |\n"
     ]
    }
   ],
   "source": [
    "print(pd.DataFrame(lists, columns=[\"#Tokens(mean)\",\"#Tokens(std)\",\"#Tokens(max)\",\"#Tokens(min)\",\"#Words(mean)\",\"#Words(std)\",\"#Words(max)\",\"#Words(min)\", \"#Chars(mean)\",\"#Chars(std)\",\"#Chars(max)\",\"#Chars(min)\"]).T.to_markdown())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}